{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celery is a powerful, asynchronous task queue/job queue system designed to handle background tasks in Python. It allows you to distribute tasks across multiple workers (processes or threads) and is commonly used for sending emails, processing large datasets, or performing scheduled tasks.\n",
    "\n",
    "Let's dive into the basics of Celery step by step.\n",
    "\n",
    "### 1. **Installation**\n",
    "\n",
    "To get started with Celery, you'll need to install it using `pip`. Additionally, Celery often works with message brokers like **RabbitMQ** or **Redis** for task queuing, so you should install the required libraries as well.\n",
    "\n",
    "For example, to use Celery with Redis as the broker:\n",
    "\n",
    "```bash\n",
    "pip install celery[redis]\n",
    "```\n",
    "\n",
    "If you want to use RabbitMQ:\n",
    "\n",
    "```bash\n",
    "pip install celery[rabbitmq]\n",
    "```\n",
    "\n",
    "You’ll also need to set up Redis or RabbitMQ separately as a message broker for Celery.\n",
    "\n",
    "### 2. **Basic Components of Celery**\n",
    "\n",
    "- **Message Broker**: A system (like Redis or RabbitMQ) that handles the sending and receiving of messages (tasks) between Celery workers and clients.\n",
    "- **Worker**: A process running in the background that picks up and executes tasks.\n",
    "- **Task**: A function that you want to execute asynchronously.\n",
    "\n",
    "### 3. **Setting Up Celery**\n",
    "\n",
    "Here's how you can set up a basic Celery application.\n",
    "\n",
    "1. Create a new file called `celery_app.py` for your Celery configuration.\n",
    "\n",
    "```python\n",
    "from celery import Celery\n",
    "\n",
    "# Create an instance of Celery and configure the broker\n",
    "app = Celery('my_celery_app', broker='redis://localhost:6379/0')\n",
    "\n",
    "# Optional: Configure the backend to store task results\n",
    "app.conf.result_backend = 'redis://localhost:6379/0'\n",
    "\n",
    "# Create a sample task\n",
    "@app.task\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- We created a Celery app instance named `my_celery_app`.\n",
    "- We're using Redis as the message broker (`redis://localhost:6379/0` is the Redis server URL).\n",
    "- We defined a simple task `add()` that adds two numbers.\n",
    "\n",
    "### 4. **Running Celery Workers**\n",
    "\n",
    "To execute the tasks, Celery needs a worker process running in the background that listens for new tasks from the message broker. You can start a worker using the following command:\n",
    "\n",
    "```bash\n",
    "celery -A celery_app worker --loglevel=info\n",
    "```\n",
    "\n",
    "- `-A celery_app`: Specifies the module where your Celery app is located (in this case, `celery_app.py`).\n",
    "- `worker`: Tells Celery to run a worker.\n",
    "- `--loglevel=info`: Outputs log information to the console.\n",
    "\n",
    "### 5. **Sending Tasks**\n",
    "\n",
    "Now that you have your worker running, you can send tasks to it from Python. For example, in another Python script or an interactive shell, you can do:\n",
    "\n",
    "```python\n",
    "from celery_app import add\n",
    "\n",
    "# Call the add task asynchronously\n",
    "result = add.delay(4, 6)\n",
    "\n",
    "# Check the task result\n",
    "print(result.get())  # Output: 10\n",
    "```\n",
    "\n",
    "Here’s what happens:\n",
    "- `add.delay(4, 6)`: Sends the task to Celery (using the message broker), where `4` and `6` are arguments to the `add` function.\n",
    "- `result.get()`: Blocks the code execution until the result of the task is ready (synchronously retrieves the result). In this case, `10`.\n",
    "\n",
    "### 6. **Monitoring Tasks**\n",
    "\n",
    "Celery provides some useful command-line utilities to monitor tasks.\n",
    "\n",
    "#### Checking Active Tasks:\n",
    "You can check which tasks are currently running using:\n",
    "\n",
    "```bash\n",
    "celery -A celery_app inspect active\n",
    "```\n",
    "\n",
    "#### Checking Reserved Tasks:\n",
    "These are tasks that have been assigned to a worker but haven't started yet.\n",
    "\n",
    "```bash\n",
    "celery -A celery_app inspect reserved\n",
    "```\n",
    "\n",
    "#### Checking Task Results:\n",
    "Celery workers can store task results, and you can retrieve them using the result backend (e.g., Redis).\n",
    "\n",
    "```python\n",
    "result = add.delay(4, 6)\n",
    "print(result.status)  # Check task status: PENDING, SUCCESS, FAILURE, etc.\n",
    "print(result.result)  # Check the actual result of the task\n",
    "```\n",
    "\n",
    "### 7. **Periodic Tasks with Celery Beat**\n",
    "\n",
    "Celery supports scheduling tasks periodically using **Celery Beat**. This is useful for cron-like scheduling.\n",
    "\n",
    "1. Install the required package for Celery Beat:\n",
    "\n",
    "```bash\n",
    "pip install celery[redis]  # Ensure you have Redis and Celery\n",
    "pip install celery[flower]  # Optional for monitoring\n",
    "```\n",
    "\n",
    "2. In your `celery_app.py` file, configure the periodic task:\n",
    "\n",
    "```python\n",
    "from celery import Celery\n",
    "from celery.schedules import crontab\n",
    "\n",
    "app = Celery('my_celery_app', broker='redis://localhost:6379/0')\n",
    "app.conf.result_backend = 'redis://localhost:6379/0'\n",
    "\n",
    "@app.task\n",
    "def say_hello():\n",
    "    return \"Hello, World!\"\n",
    "\n",
    "# Celery Beat schedule configuration\n",
    "app.conf.beat_schedule = {\n",
    "    'say-hello-every-10-seconds': {\n",
    "        'task': 'celery_app.say_hello',  # Specify task name\n",
    "        'schedule': 10.0,  # Schedule task every 10 seconds\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, the `say_hello()` task will be run every 10 seconds.\n",
    "\n",
    "3. Start Celery Beat with:\n",
    "\n",
    "```bash\n",
    "celery -A celery_app beat --loglevel=info\n",
    "```\n",
    "\n",
    "You also need to have the worker running:\n",
    "\n",
    "```bash\n",
    "celery -A celery_app worker --loglevel=info\n",
    "```\n",
    "\n",
    "Now, the task will execute periodically as defined in the schedule.\n",
    "\n",
    "### 8. **Error Handling and Retries**\n",
    "\n",
    "Celery provides ways to handle task failures and retry them.\n",
    "\n",
    "#### Task Retries\n",
    "\n",
    "You can configure tasks to retry automatically if they fail.\n",
    "\n",
    "```python\n",
    "@app.task(bind=True, max_retries=3)\n",
    "def faulty_task(self, x, y):\n",
    "    try:\n",
    "        return x / y\n",
    "    except ZeroDivisionError as e:\n",
    "        self.retry(exc=e, countdown=5)  # Retry after 5 seconds\n",
    "```\n",
    "\n",
    "- **bind=True**: Binds the task to `self` so that it can access its context.\n",
    "- **max_retries=3**: Limits the task to retry 3 times.\n",
    "- **self.retry()**: Used to retry the task after an exception, with an optional delay (`countdown=5`).\n",
    "\n",
    "### 9. **Task Time Limits**\n",
    "\n",
    "You can limit how long a task can run by setting a time limit.\n",
    "\n",
    "```python\n",
    "@app.task(time_limit=10)\n",
    "def long_running_task():\n",
    "    # Some long-running task\n",
    "    pass\n",
    "```\n",
    "\n",
    "This ensures that the task will be forcefully terminated if it runs longer than 10 seconds.\n",
    "\n",
    "### 10. **Monitoring Celery with Flower**\n",
    "\n",
    "**Flower** is a real-time web-based monitoring tool for Celery. You can install it with:\n",
    "\n",
    "```bash\n",
    "pip install flower\n",
    "```\n",
    "\n",
    "Then run it with:\n",
    "\n",
    "```bash\n",
    "celery -A celery_app flower\n",
    "```\n",
    "\n",
    "This will start a web server at `http://localhost:5555`, where you can monitor your tasks, queues, and workers.\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. **Celery** is a task queue system that allows you to run tasks asynchronously.\n",
    "2. Install Celery and choose a broker (like **Redis** or **RabbitMQ**).\n",
    "3. Define tasks using the `@app.task` decorator.\n",
    "4. Run Celery workers using `celery -A your_app worker`.\n",
    "5. Use **Celery Beat** for periodic tasks.\n",
    "6. **Flower** can be used for real-time monitoring of Celery.\n",
    "\n",
    "Celery is highly customizable, and these are just the basics! You can scale Celery to multiple workers, handle large queues, and integrate it with Django, Flask, or other frameworks. Let me know if you want to explore any specific feature of Celery!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
