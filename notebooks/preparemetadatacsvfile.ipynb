{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required fields\n",
    "\n",
    "- Album title - Name of the release.\n",
    "- UPC - FUGA's system supports both 13 & 12 digit UPCs. Where your UPC has a leading 0, please ensure that this is consistent across all references to the product.\n",
    "- Catalog number - The unique identifier for the release, as assigned by the label (if you do not have a catalog number, you can use the UPC as catalog number)\n",
    "- Primary artists - Only fill the Primary Artists’ names here, do not include any Featuring Artists. Always separate multiple artist names by a | (e.g.: Shakira | Beyonce)\n",
    "- (Consumer) Release date - Very important to check that you format this column as a date, not as a number or text Format: YYYY-MM-DD\n",
    "- Main genre\n",
    "  - Must be one of the following genres:\n",
    "    Alternative;\n",
    "    Audiobooks;\n",
    "    Blues;\n",
    "    Children's Music;\n",
    "    Classical;\n",
    "    Comedy;\n",
    "    Country;\n",
    "    Dance;\n",
    "    Electronic;\n",
    "    Folk;\n",
    "    Hip Hop/Rap;\n",
    "    Holiday Inspirational;\n",
    "    Jazz;\n",
    "    Latin;\n",
    "    New Age;\n",
    "    Opera;\n",
    "    Pop;\n",
    "    R&B/Soul;\n",
    "    Reggae;\n",
    "    Rock;\n",
    "    Spoken Word;\n",
    "    Soundtrack;\n",
    "    Vocal;\n",
    "    World\n",
    "\n",
    "- CLine (Copyright) year - Please use 4 digit years (e.g.: 2020)\n",
    "- CLine (Copyright) name - © line: the name of the rights owner, i.e. the current owner of the copyright in the relevant work (e.g.: cover artwork, inlay cards, etc).\n",
    "- PLine (Copyright) year - Please use 4 digit years (e.g.: 2020)\n",
    "- Pline (Copyright) name - ℗ line: the name of the rights owner, i.e. the current owner of the rights in the original sound recording/masters\n",
    "- Parental advisory - Use a Y to indicate yes and a N to indicate no\n",
    "- Album format - Album format must be one of the following values:\n",
    "        Single;\n",
    "        EP;\n",
    "        Album;\n",
    "        Box-set.\n",
    "- Number of volumes - 1 \n",
    "- Territories - \tTerritories can contain World or territory codes separated by | (e g.: IT|FR|US). You can find the list of territory codes on this site: http://www.iso.org/iso/country_codes/iso_3166_code_lists/english_country_names_and_code_elements.htm\n",
    "If you leave this field empty it will default to World\n",
    "- Track title - Track name. Note: Do not include the release version here!\n",
    "- ISRC - You should enter ISRCs without the separating dashes, otherwise invalid codes will cause ingestion errors (e.g.: ITONB2000013)\n",
    "- Track Primary artists - Only fill the Primary Artists’ names here, do not include any Featuring Artists.\n",
    "Always separate multiple artist names by a | (e.g.: Shakira | Beyonce)\n",
    "- Volume number - If there is more than one volume, which volume is this track on?\n",
    "- Track Main genre - Must be one of the following genres:\n",
    "            Alternative;\n",
    "            Audiobooks;\n",
    "            Blues;\n",
    "            Children's Music;\n",
    "            Classical;\n",
    "            Comedy;\n",
    "            Country;\n",
    "            Dance;\n",
    "            Electronic;\n",
    "            Folk;\n",
    "            Hip Hop/Rap;\n",
    "            Holiday Inspirational;\n",
    "            Jazz;\n",
    "            Latin;\n",
    "            New Age;\n",
    "            Opera;\n",
    "            Pop;\n",
    "            R&B/Soul;\n",
    "            Reggae;\n",
    "            Rock;\n",
    "            Spoken Word;\n",
    "            Soundtrack;\n",
    "            Vocal;\n",
    "            World\n",
    "- Audio Language - The Language of the Audio Recording, or Language of performance (e.g.: EN, IT, FR,… for Instrumental you can add ZXX)\n",
    "- Lyrics - Lyrics of the recording. Leave blank if the recording is instrumental\n",
    "- Available separately - Use a Y to indicate yes and a N to indicate no\n",
    "- Track Parental advisory - Use a Y to indicate yes and a N to indicate no\n",
    "- Writers - Writers & Publishers (columns AZ & BA) are complementary columns. There must be an equal number of entries in both columns (e.g.: Writer A| Writer B| Writer C & Publisher X| Publisher Y| Publisher Y).\n",
    "As per this example there does not need to be an equal number of writers and publishers, but there must be an equal number of entries in both columns.\n",
    "- Publishers - Writers & Publishers (columns AZ & BA) are complementary columns. There must be an equal number of entries in both columns (e.g.: Writer A| Writer B| Writer C & Publisher X| Publisher Y| Publisher Y).\n",
    "As per this example there does not need to be an equal number of writers and publishers, but there must be an equal number of entries in both columns.\n",
    "- Track Sequence - Only fill in the tracks sequence if the track order in the excel sheet differs from the hard drive\n",
    "- Track Catalog Tier - Track Catalog Tier should be one of the following:\n",
    "        Free,\n",
    "        Back,\n",
    "        Mid,\n",
    "        Front\n",
    "- Original file name - The name of the audio file (e.g.: Besttrack0035.wav). The track names should be exactly the same as they are on the FTP.\n",
    "Recommended Format: UPC_volumenumber_tracknumber.fileextension Example: 472947291729_01_09.wav\n",
    "- Original release date - Very important to check that you format this column as a date, not as a number or text. Format: YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "def prepare_music_csv(file_name, album_data, track_data):\n",
    "    \"\"\"\n",
    "    Prepares a CSV file with album and track metadata.\n",
    "\n",
    "    :param file_name: The name of the CSV file to save.\n",
    "    :param album_data: A dictionary containing album-level information.\n",
    "    :param track_data: A list of dictionaries, each containing track-level information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define album-level fields\n",
    "    album_fields = [\n",
    "        'Product', 'Album title', 'Album version', 'UPC', 'Catalog number', \n",
    "        'Primary artists', 'Featuring Artists', 'Release date', 'Main genre', \n",
    "        'CLine (Copyright) year', 'CLine (Copyright) name', 'PLine (Copyright) year', \n",
    "        'PLine (Copyright) name', 'Parental advisory', 'Album format', 'Number of volumes', \n",
    "        'Territories', 'Excluded territories', 'Language(Metadata)', 'Catalog Tier'\n",
    "    ]\n",
    "\n",
    "    # Define track-level fields\n",
    "    track_fields = [\n",
    "        'Track title', 'Track version', 'ISRC', 'Track Primary artists', 'Track Featuring Artists', \n",
    "        'Volume number', 'Track Main genre', 'Track Main subgenre', 'Track Language (Metadata)', \n",
    "        'Audio Language', 'Lyrics', 'Available separately', 'Track Parental advisory', \n",
    "        'Contributing artists', 'Composers', 'Lyricists', 'Remixers', 'Performers', 'Producers', \n",
    "        'Writers', 'Publishers', 'Track Sequence', 'Track Catalog Tier', 'Original file name', \n",
    "        'Original release date'\n",
    "    ]\n",
    "    \n",
    "    # Combine album and track fields for CSV headers\n",
    "    fieldnames = album_fields + track_fields\n",
    "\n",
    "    # Write CSV file\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Merge album and track data\n",
    "        for track in track_data:\n",
    "            # Merge album and track dictionaries for a single row\n",
    "            combined_data = {**album_data, **track}\n",
    "            writer.writerow(combined_data)\n",
    "\n",
    "# Sample data\n",
    "album_data = {\n",
    "    'Product': 'Album',\n",
    "    'Album title': 'The Great Album',\n",
    "    'Album version': 'Studio Version',\n",
    "    'UPC': '123456789012',\n",
    "    'Catalog number': 'CAT1234',\n",
    "    'Primary artists': 'Shakira',\n",
    "    'Featuring Artists': '',\n",
    "    'Release date': '2024-09-01',\n",
    "    'Main genre': 'Pop',\n",
    "    'CLine (Copyright) year': '2024',\n",
    "    'CLine (Copyright) name': 'Shakira Music Inc.',\n",
    "    'PLine (Copyright) year': '2024',\n",
    "    'PLine (Copyright) name': 'Shakira Music Inc.',\n",
    "    'Parental advisory': 'N',\n",
    "    'Album format': 'Album',\n",
    "    'Number of volumes': '1',\n",
    "    'Territories': 'World',\n",
    "    'Excluded territories': '',\n",
    "    'Language(Metadata)': 'EN',\n",
    "    'Catalog Tier': 'Front'\n",
    "}\n",
    "\n",
    "track_data = [\n",
    "    {\n",
    "        'Track title': 'First Track',\n",
    "        'Track version': 'Remix Version',\n",
    "        'ISRC': 'US1234567890',\n",
    "        'Track Primary artists': 'Shakira',\n",
    "        'Track Featuring Artists': 'Beyonce',\n",
    "        'Volume number': '1',\n",
    "        'Track Main genre': 'Pop',\n",
    "        'Track Main subgenre': 'Dance',\n",
    "        'Track Language (Metadata)': 'EN',\n",
    "        'Audio Language': 'EN',\n",
    "        'Lyrics': 'Some lyrics here...',\n",
    "        'Available separately': 'Y',\n",
    "        'Track Parental advisory': 'N',\n",
    "        'Contributing artists': 'Artist A|Artist B',\n",
    "        'Composers': 'Composer A|Composer B',\n",
    "        'Lyricists': 'Lyricist A|Lyricist B',\n",
    "        'Remixers': 'Remixer A',\n",
    "        'Performers': 'Performer A|Performer B',\n",
    "        'Producers': 'Producer A',\n",
    "        'Writers': 'Writer A|Writer B',\n",
    "        'Publishers': 'Publisher A|Publisher B',\n",
    "        'Track Sequence': '1',\n",
    "        'Track Catalog Tier': 'Front',\n",
    "        'Original file name': '123456789012_01_01.wav',\n",
    "        'Original release date': '2024-09-01'\n",
    "    },\n",
    "    # Add more track data here...\n",
    "]\n",
    "\n",
    "# Prepare CSV\n",
    "prepare_music_csv('album_tracks.csv', album_data, track_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to usable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3\n",
    "# coding:utf8\n",
    "import csv\n",
    "\n",
    "data = [\n",
    "    [\"American\", \"美国人\"],\n",
    "    [\"Chinese\", \"中国人\"],\n",
    "    [\"Trưởng phòng Marketing\", \"và Phát triển kinh doanh\"],\n",
    "]\n",
    "\n",
    "with open(\"results.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerows(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write on google sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# Step 1: Setup Google Sheets API\n",
    "def setup_gspread(creds_file, sheet_name):\n",
    "    scope = [\n",
    "        \"https://spreadsheets.google.com/feeds\",\n",
    "        \"https://www.googleapis.com/auth/drive\",\n",
    "    ]\n",
    "    creds = Credentials.from_service_account_file(creds_file, scopes=scope)\n",
    "    client = gspread.authorize(creds)\n",
    "    sheet = client.open(sheet_name).sheet1  # Get the first sheet\n",
    "    return sheet\n",
    "\n",
    "\n",
    "# Step 2: Write CSV data to Google Sheets\n",
    "def write_csv_to_google_sheets(sheet, csv_file):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Clear existing sheet data\n",
    "    sheet.clear()\n",
    "    # Write the DataFrame to Google Sheets\n",
    "    sheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "\n",
    "\n",
    "# Step 3: Write database data to Google Sheets\n",
    "def write_db_to_google_sheets(sheet, db_url, query):\n",
    "    # Connect to the database\n",
    "    engine = create_engine(db_url)\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(query, conn)\n",
    "\n",
    "    # Clear existing sheet data\n",
    "    sheet.clear()\n",
    "    # Write the DataFrame to Google Sheets\n",
    "    sheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
    "\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Google Sheets API credentials and sheet name\n",
    "    creds_file = \"path/to/your/credentials.json\"\n",
    "    sheet_name = \"Your Google Sheet Name\"\n",
    "\n",
    "    # CSV file path\n",
    "    csv_file = \"path/to/your/file.csv\"\n",
    "\n",
    "    # Database connection (PostgreSQL example)\n",
    "    db_url = \"postgresql://username:password@localhost:5432/your_database\"\n",
    "    query = \"SELECT * FROM your_table\"\n",
    "\n",
    "    # Set up Google Sheets\n",
    "    sheet = setup_gspread(creds_file, sheet_name)\n",
    "\n",
    "    # Write CSV data to Google Sheets\n",
    "    write_csv_to_google_sheets(sheet, csv_file)\n",
    "\n",
    "    # Write database data to Google Sheets\n",
    "    write_db_to_google_sheets(sheet, db_url, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 200000\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "# Create two threads\n",
    "t1 = threading.Thread(target=increment)\n",
    "t2 = threading.Thread(target=increment)\n",
    "\n",
    "# Start both threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Wait for both threads to complete\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(\"Counter:\", counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 200000\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def increment():\n",
    "    global counter\n",
    "    for _ in range(100000):\n",
    "        with lock:  # Acquire the lock before accessing the shared resource\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "# Create and start two threads\n",
    "t1 = threading.Thread(target=increment)\n",
    "t2 = threading.Thread(target=increment)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "print(\"Counter:\", counter)  # Now the result should be 200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "rlock = threading.RLock()\n",
    "\n",
    "\n",
    "def recursive_function():\n",
    "    with rlock:\n",
    "        print(\"Lock acquired\")\n",
    "        if some_condition:\n",
    "            recursive_function()  # Re-acquire the same lock in the recursion\n",
    "\n",
    "\n",
    "# Only one thread can acquire the lock, even during recursion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource accessed\n",
      "Resource accessed\n",
      "Resource accessed\n",
      "Resource accessed\n",
      "Resource accessed\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "semaphore = threading.Semaphore(3)  # Allow up to 3 threads at once\n",
    "\n",
    "\n",
    "def access_shared_resource():\n",
    "    with semaphore:\n",
    "        print(\"Resource accessed\")\n",
    "        # Do some work\n",
    "\n",
    "\n",
    "# Create multiple threads\n",
    "threads = []\n",
    "for _ in range(5):\n",
    "    t = threading.Thread(target=access_shared_resource)\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data consumed: 1\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "condition = threading.Condition()\n",
    "shared_data = []\n",
    "\n",
    "\n",
    "def producer():\n",
    "    with condition:\n",
    "        shared_data.append(1)\n",
    "        condition.notify()  # Signal a thread that the data is available\n",
    "\n",
    "\n",
    "def consumer():\n",
    "    with condition:\n",
    "        condition.wait()  # Wait until the condition is signaled\n",
    "        print(\"Data consumed:\", shared_data.pop())\n",
    "\n",
    "\n",
    "# Create threads for producer and consumer\n",
    "t1 = threading.Thread(target=consumer)\n",
    "t2 = threading.Thread(target=producer)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def worker(q):\n",
    "    q.put(\"Data from worker\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    p1 = multiprocessing.Process(target=worker, args=(q,))\n",
    "    p2 = multiprocessing.Process(target=worker, args=(q,))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    while not q.empty():\n",
    "        print(q.get())  # Get data from the queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "def generate_presigned_url(bucket_name, object_name, expiration=3600):\n",
    "    try:\n",
    "        response = s3_client.generate_presigned_url(\n",
    "            \"put_object\", Params={\"Bucket\": bucket_name, \"Key\": object_name}, ExpiresIn=expiration\n",
    "        )\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return None\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload a file to AWS S3 in a Flutter application, you’ll need to follow these steps:\n",
    "\n",
    "1. **Set up AWS S3 bucket and credentials**: \n",
    "   - Create an S3 bucket on AWS.\n",
    "   - Generate the necessary access key and secret key from the AWS IAM console.\n",
    "   \n",
    "2. **Configure AWS S3 access**: \n",
    "   - Use Amazon’s SDK for Dart (or Flutter) to interact with S3. Alternatively, you can use HTTP requests signed with AWS Signature Version 4 (a bit more manual work).\n",
    "\n",
    "3. **Flutter dependencies**: \n",
    "   - You will use the `amazon_cognito_identity_dart_2` package (for temporary credentials using Cognito if needed) and the `dio` package for handling file uploads. The `dio` package allows you to easily handle multipart file uploads.\n",
    "   - Optionally, use the `flutter_file_picker` package to let the user pick a file from the device.\n",
    "\n",
    "Here’s how you can upload a file to AWS S3 using **Pre-signed URLs** (recommended for security reasons) in Flutter.\n",
    "\n",
    "### Step 1: Add Dependencies to `pubspec.yaml`\n",
    "Add the following dependencies in your `pubspec.yaml` file.\n",
    "\n",
    "```yaml\n",
    "dependencies:\n",
    "  flutter:\n",
    "    sdk: flutter\n",
    "  dio: ^5.1.0  # For HTTP requests and file uploads\n",
    "  flutter_file_picker: ^5.0.0  # For selecting files from the device\n",
    "```\n",
    "\n",
    "Run `flutter pub get` to install the dependencies.\n",
    "\n",
    "### Step 2: Get the Pre-signed URL from Backend\n",
    "\n",
    "Before uploading to S3, you’ll need a **pre-signed URL** from your backend (or AWS Lambda). This URL allows you to securely upload files to S3 without exposing your AWS credentials. You can use this pre-signed URL with a `PUT` request to upload files.\n",
    "\n",
    "Here’s an example of how your backend might generate a pre-signed URL (assuming you're using Python with `boto3`):\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def generate_presigned_url(bucket_name, object_name, expiration=3600):\n",
    "    try:\n",
    "        response = s3_client.generate_presigned_url('put_object',\n",
    "            Params={'Bucket': bucket_name, 'Key': object_name},\n",
    "            ExpiresIn=expiration)\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return None\n",
    "\n",
    "    return response\n",
    "```\n",
    "\n",
    "This will return a URL that you can use to upload the file directly to S3. Pass this URL back to your Flutter app.\n",
    "\n",
    "### Step 3: Upload File to S3 in Flutter\n",
    "\n",
    "Now, let’s implement the Flutter code that allows the user to pick a file and upload it to the pre-signed URL using `dio`.\n",
    "\n",
    "```dart\n",
    "import 'dart:io';\n",
    "import 'package:dio/dio.dart';\n",
    "import 'package:flutter/material.dart';\n",
    "import 'package:flutter_file_picker/flutter_file_picker.dart';\n",
    "\n",
    "class S3FileUploader extends StatefulWidget {\n",
    "  @override\n",
    "  _S3FileUploaderState createState() => _S3FileUploaderState();\n",
    "}\n",
    "\n",
    "class _S3FileUploaderState extends State<S3FileUploader> {\n",
    "  File? _file;\n",
    "  bool _isUploading = false;\n",
    "  String? _uploadedFileUrl;\n",
    "\n",
    "  // Use Dio for file uploads\n",
    "  Dio dio = Dio();\n",
    "\n",
    "  // Function to pick a file from the device\n",
    "  Future<void> pickFile() async {\n",
    "    final result = await FilePicker.platform.pickFiles(\n",
    "      type: FileType.any,\n",
    "      allowMultiple: false,\n",
    "    );\n",
    "\n",
    "    if (result != null && result.files.isNotEmpty) {\n",
    "      setState(() {\n",
    "        _file = File(result.files.single.path!);\n",
    "      });\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Function to upload a file using a pre-signed URL\n",
    "  Future<void> uploadFileToS3(String presignedUrl) async {\n",
    "    if (_file == null) return;\n",
    "\n",
    "    setState(() {\n",
    "      _isUploading = true;\n",
    "    });\n",
    "\n",
    "    try {\n",
    "      String fileName = _file!.path.split('/').last;\n",
    "\n",
    "      // Use Dio to make the PUT request with the file to the pre-signed URL\n",
    "      Response response = await dio.put(\n",
    "        presignedUrl,\n",
    "        data: _file!.openRead(),\n",
    "        options: Options(\n",
    "          headers: {\n",
    "            \"Content-Type\": \"multipart/form-data\",\n",
    "          },\n",
    "        ),\n",
    "      );\n",
    "\n",
    "      if (response.statusCode == 200) {\n",
    "        // File uploaded successfully\n",
    "        setState(() {\n",
    "          _uploadedFileUrl = presignedUrl.split('?').first; // Remove query params to get the URL\n",
    "        });\n",
    "      } else {\n",
    "        print(\"Failed to upload file: ${response.statusCode}\");\n",
    "      }\n",
    "    } catch (e) {\n",
    "      print(\"Error uploading file: $e\");\n",
    "    } finally {\n",
    "      setState(() {\n",
    "        _isUploading = false;\n",
    "      });\n",
    "    }\n",
    "  }\n",
    "\n",
    "  @override\n",
    "  Widget build(BuildContext context) {\n",
    "    return Scaffold(\n",
    "      appBar: AppBar(\n",
    "        title: Text('S3 File Uploader'),\n",
    "      ),\n",
    "      body: Center(\n",
    "        child: Column(\n",
    "          mainAxisAlignment: MainAxisAlignment.center,\n",
    "          children: [\n",
    "            ElevatedButton(\n",
    "              onPressed: pickFile,\n",
    "              child: Text('Pick a file'),\n",
    "            ),\n",
    "            if (_file != null) Text('Selected File: ${_file!.path}'),\n",
    "            SizedBox(height: 20),\n",
    "            ElevatedButton(\n",
    "              onPressed: () async {\n",
    "                // Here you need to fetch the pre-signed URL from your backend\n",
    "                String presignedUrl = await getPresignedUrlFromBackend();\n",
    "                await uploadFileToS3(presignedUrl);\n",
    "              },\n",
    "              child: _isUploading ? CircularProgressIndicator() : Text('Upload to S3'),\n",
    "            ),\n",
    "            if (_uploadedFileUrl != null)\n",
    "              Column(\n",
    "                children: [\n",
    "                  Text('File uploaded successfully!'),\n",
    "                  Text('File URL: $_uploadedFileUrl'),\n",
    "                ],\n",
    "              ),\n",
    "          ],\n",
    "        ),\n",
    "      ),\n",
    "    );\n",
    "  }\n",
    "\n",
    "  // Mock function to simulate getting a pre-signed URL from a backend\n",
    "  Future<String> getPresignedUrlFromBackend() async {\n",
    "    // Simulate a network call to get the pre-signed URL\n",
    "    await Future.delayed(Duration(seconds: 2));\n",
    "    \n",
    "    // Replace with your actual pre-signed URL\n",
    "    return 'https://your-bucket.s3.amazonaws.com/your-file-key?AWSAccessKeyId=your-access-key&Signature=your-signature&Expires=timestamp';\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Key Points:\n",
    "1. **File Picker**: The user selects a file from their device using the `flutter_file_picker` package.\n",
    "2. **Dio**: The `dio` package is used to upload the file to S3 using the pre-signed URL. The `dio.put` method is used to send a `PUT` request along with the file stream.\n",
    "3. **Pre-signed URL**: The URL is fetched from a backend (or hardcoded for testing) and used to upload the file securely.\n",
    "\n",
    "### Step 4: Testing\n",
    "\n",
    "1. Ensure your backend is generating pre-signed URLs.\n",
    "2. Run your Flutter app, pick a file, and upload it using the pre-signed URL.\n",
    "\n",
    "---\n",
    "\n",
    "This example focuses on using **pre-signed URLs**, which is a secure and scalable way to handle file uploads to S3, as it doesn't expose your AWS credentials in the client app. If you need a more integrated solution with AWS SDKs directly in Flutter, you can look into using **Amplify Flutter**, which wraps AWS services, but it can be more complex to set up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
